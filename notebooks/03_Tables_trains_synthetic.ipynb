{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab3c6c3",
   "metadata": {},
   "source": [
    "# Ingeniería de Características y Selección Basada en Correlación\n",
    "\n",
    "En todo proceso de modelado supervisado, la calidad de las variables de entrada puede llegar a ser tan determinante como el propio algoritmo. En este notebook proponemos una estrategia estadística para segmentar nuestro espacio de características en dos grupos: uno con las **columnas más fuertemente correlacionadas** y otro con aquellas de **correlación moderada** con respecto a la variable objetivo. De este modo, podremos entrenar modelos con distintos niveles de información y comparar directamente su desempeño.\n",
    "\n",
    "Primero, ampliamos nuestro set original de datos generando nuevas variables —por ejemplo, interacciones o polinomios— que potencialmente capten patrones no lineales. A continuación, medimos la relevancia de cada característica mediante el coeficiente de correlación de Pearson:\n",
    "\n",
    "$$\n",
    "r_i = \\frac{\\mathrm{cov}(X_i, Y)}{\\sigma_{X_i}\\,\\sigma_{Y}}\n",
    "$$\n",
    "\n",
    "y cuantificamos la redundancia usando el **Factor de Inflación de la Varianza (VIF)**:\n",
    "\n",
    "$$\n",
    "\\mathrm{VIF}_i = \\frac{1}{1 - R_i^2}\n",
    "$$\n",
    "\n",
    "donde $R_i^2$ es el coeficiente de determinación al ajustar $X_i$ como variable dependiente frente al resto de columnas del dataset.\n",
    "\n",
    "Para decidir qué columnas pasan a cada grupo, estudiamos la **distribución empírica** de los valores $|r_i|$. Definimos dos umbrales basados en percentiles:\n",
    "\n",
    "- El **66.6 %** señala el corte para nuestra **Tabla “Relevante”** (correlaciones más altas).  \n",
    "- El **33.3 %** marca el límite mínimo para la **Tabla “Semi-Relevante”** (correlaciones moderadas).\n",
    "\n",
    "El resto de las variables, con $|r_i|$ por debajo del percentil 33.3, queda fuera del conjunto de entrenamiento por aportar muy poca señal.\n",
    "\n",
    "En la siguiente sección presentamos una visualización con una curva normal de referencia:\n",
    "\n",
    "![Distribución de correlaciones con la variable objetivo](Graphics\\Ej_filtrado_correlacion.png)\n",
    "\n",
    "Las áreas sombreadas a la derecha de cada umbral permiten apreciar de un solo vistazo la proporción de columnas seleccionadas.\n",
    "\n",
    "Finalmente, crearemos dos DataFrames —uno con las columnas del grupo “Relevante” y otro con las del grupo “Semi-Relevante”— y aplicaremos la **ecuación de pronóstico** proporcionada por el concurso para predecir el número de unidades vendidas en los 16 días siguientes. Evaluaremos cada modelo comparando métricas de error de regresión como **MAE** (Error Absoluto Medio) y **RMSE** (Raíz del Error Cuadrático Medio) para determinar si el uso de un conjunto de variables más amplio (Semi-Relevante) mejora o empeora las predicciones frente al conjunto más restringido (Relevante). Esta metodología aporta rigor estadístico y flexibilidad para explorar el trade-off entre complejidad del modelo y precisión de la predicción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89648a4",
   "metadata": {},
   "source": [
    "Claro, aquí tienes una versión mejorada, más clara, coherente y profesional del texto, junto con la fórmula de variación porcentual diaria y un ejemplo más estructurado del análisis de desfase:\n",
    "\n",
    "---\n",
    "\n",
    "Vamos a utilizar como plantilla base la tabla `train`, a partir de la cual crearemos dos nuevas copias denominadas `Test_50_insight` y `Test_100_insight`.\n",
    "\n",
    "Planeo trabajar con el DataFrame `oil`, del cual extraeremos las columnas `date` y `dcoilwtico` (precio del petróleo WTI). Con esta información, calcularemos la **variación porcentual diaria del precio del petróleo** y la almacenaremos en una nueva columna llamada `oil_price`.\n",
    "\n",
    "Esta columna será posteriormente combinada con la tabla `train`, alineando los valores por la columna `date`, para así conocer cómo varió el precio del petróleo cada día específico.\n",
    "\n",
    "### Cálculo de la variación porcentual diaria\n",
    "\n",
    "La fórmula para calcular la variación porcentual diaria es:\n",
    "\n",
    "$$\n",
    "\\text{variación}_{t} = \\frac{P_{t} - P_{t-1}}{P_{t-1}} \\times 100\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "* $P_t$ es el precio del petróleo en el día actual\n",
    "* $P_{t-1}$ es el precio del día anterior\n",
    "\n",
    "### Justificación del desfase temporal\n",
    "\n",
    "Inicialmente se pensó en **adelantar un día** la variable `oil_price`, ya que el precio del petróleo actual podría influir en las decisiones del mercado **al día siguiente**, no en el mismo día en que se registra el precio. Sin embargo, para tomar una decisión informada, se propone realizar un análisis de **correlación** entre la variable `oil_price` y otras variables objetivo, considerando tres escenarios distintos:\n",
    "\n",
    "1. **Desfase -1 (precio del día anterior):**\n",
    "   Se utiliza el precio del petróleo del día anterior para predecir el comportamiento del día actual.\n",
    "2. **Sin desfase (precio actual):**\n",
    "   Se utiliza el precio del petróleo del mismo día.\n",
    "3. **Desfase +1 (precio del día siguiente):**\n",
    "   Se usa el precio del día siguiente, bajo la hipótesis de que el precio de hoy refleja la reacción al comportamiento del día anterior.\n",
    "\n",
    "### Ejemplo ilustrativo de desfases\n",
    "\n",
    "Aquí tienes un ejemplo más claro de cómo funciona el desfase en los precios del petróleo. Supongamos que los precios diarios son los siguientes:\n",
    "\n",
    "| Fecha      | Precio WTI |\n",
    "| ---------- | ---------- |\n",
    "| 17 de mayo | 1.01       |\n",
    "| 18 de mayo | 1.05       |\n",
    "| 19 de mayo | 1.02       |\n",
    "\n",
    "Y que nuestra plantilla `train` contiene las mismas fechas como índice para unir:\n",
    "\n",
    "| Fecha      | … otras columnas … |\n",
    "| ---------- | ------------------ |\n",
    "| 17 de mayo | …                  |\n",
    "| 18 de mayo | …                  |\n",
    "| 19 de mayo | …                  |\n",
    "\n",
    "Ahora veamos los tres escenarios:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Desfase -1 (precio del día anterior)\n",
    "\n",
    "Aquí asignamos al 18 de mayo el precio del 17 de mayo, y al 19 de mayo el del 18 de mayo:\n",
    "\n",
    "| Fecha (train) | oil\\_price (t-1) |\n",
    "| ------------- | ---------------- |\n",
    "| 17 de mayo    | —                |\n",
    "| 18 de mayo    | 1.01             |\n",
    "| 19 de mayo    | 1.05             |\n",
    "\n",
    "* **Interpretación**: Para el 18 usas el precio del 17, asumiendo que el mercado reacciona con un día de retraso.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Sin desfase (precio del mismo día)\n",
    "\n",
    "Asignamos a cada fecha su propio precio:\n",
    "\n",
    "| Fecha (train) | oil\\_price (t) |\n",
    "| ------------- | -------------- |\n",
    "| 17 de mayo    | 1.01           |\n",
    "| 18 de mayo    | 1.05           |\n",
    "| 19 de mayo    | 1.02           |\n",
    "\n",
    "* **Interpretación**: El modelo ve el precio del petróleo del mismo día.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Desfase +1 (precio del día siguiente)\n",
    "\n",
    "Aquí adelantamos un día: al 17 de mayo le ponemos el precio del 18, y al 18 el del 19:\n",
    "\n",
    "| Fecha (train) | oil\\_price (t+1) |\n",
    "| ------------- | ---------------- |\n",
    "| 17 de mayo    | 1.05             |\n",
    "| 18 de mayo    | 1.02             |\n",
    "| 19 de mayo    | —                |\n",
    "\n",
    "* **Interpretación**: El modelo “ve” el precio que estará disponible mañana, ideal si crees que las señales del petróleo ya anticipan movimientos un día antes.\n",
    "\n",
    "---\n",
    "\n",
    "Con estos tres conjuntos de datos podrás calcular el coeficiente de correlación de cada versión de `oil_price` con tu variable objetivo y decidir cuál desfase aporta más valor predictivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82244ca8",
   "metadata": {},
   "source": [
    "## `HOLIDAYS_Events`\n",
    "\n",
    "Este es otro *dataframe* que contiene columnas con información útil que podemos aprovechar.  \n",
    "La idea es crear dos nuevas columnas en nuestro conjunto de datos `train`:\n",
    "\n",
    "1. **`es_festivo`**: una columna booleana que indicará si la fecha corresponde a un día festivo (`True` o `False`).\n",
    "2. **`tipo_festivo`**: una columna categórica que especificará el tipo de día festivo. Para facilitar su uso en modelos de IA (que no aceptan variables de tipo `string` directamente), se codificará de forma numérica:\n",
    "\n",
    "   - `0`: festivo local  \n",
    "   - `1`: festivo regional  \n",
    "   - `2`: festivo nacional\n",
    "\n",
    "Estas nuevas columnas nos permitirán enriquecer el análisis y posiblemente mejorar el rendimiento del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c446b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfcfee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa. Versión de PostgreSQL: PostgreSQL 17.5 on x86_64-pc-linux-musl, compiled by gcc (Alpine 14.2.0) 14.2.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "# %%python\n",
    "import yaml\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from pathlib import Path\n",
    "\n",
    "# 0. (Opcional) verifica tu cwd para entender dónde estás\n",
    "# import os\n",
    "# print(\"CWD:\", os.getcwd())\n",
    "\n",
    "# 1. Construye la ruta absoluta al root del repo (un nivel arriba de notebooks)\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# 2. Señala tu config.yaml dentro de config/\n",
    "config_path = project_root / \"config\" / \"config.yaml\"\n",
    "\n",
    "# 3. Carga el YAML\n",
    "with config_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "db = cfg[\"database\"]\n",
    "\n",
    "# 4. Conecta a PostgreSQL y prueba\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=db[\"host\"],\n",
    "        port=db[\"port\"],\n",
    "        user=db[\"user\"],\n",
    "        password=db[\"password\"],\n",
    "        dbname=db[\"database\"]\n",
    "    )\n",
    "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    cur.execute(\"SELECT version();\")\n",
    "    version = cur.fetchone()[\"version\"]\n",
    "    print(f\"✅ Conexión exitosa. Versión de PostgreSQL: {version}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al conectar: {e}\")\n",
    "finally:\n",
    "    if 'conn' in locals() and conn:\n",
    "        conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
